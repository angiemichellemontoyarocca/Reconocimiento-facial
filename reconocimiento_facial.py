# -*- coding: utf-8 -*-
"""reconocimiento facial

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12sWIGkLTRM2yGRBa-MWnUEgfBiWNLqG_

##Instalamos la libreria Face_recognition
"""

!pip install face_recognition

"""##importamos las librerias"""

!pip uninstall -y dlib
!pip install dlib==19.18.0

from IPython.display import display, Javascript, Image
from google.colab.output import eval_js
from base64 import b64decode, b64encode
import cv2
import numpy as np
import PIL
import io
import html
import time
import face_recognition

"""*   face_recognition: para realizar el reconocimiento facial.
*   IPython.display: facilita la interacción con la cámara y la visualización de imágenes.

*   cv2 (OpenCV): para el procesamiento de imágenes.
*   base64 y eval_js: convierten imágenes entre diferentes formatos y permiten usar JavaScript en Colab para acceder a la cámara.

##Funcion para convertir un Objeto de JavaScript en una imagen en Opencv

*   Convierte la imagen capturada desde la cámara de formato JavaScript a un array de OpenCV para su procesamiento posterior.
*   toma la imagen en formato base64 desde JavaScript y la convierte en un formato compatible con OpenCV para realizar el procesamiento de imágenes.
"""

# function
def js_to_image(js_reply):
  """
  Params:
          js_reply: JavaScript object containing image from webcam
  Returns:
          img: OpenCV BGR image
  """
  # decode base64 image
  image_bytes = b64decode(js_reply.split(',')[1])
  # convert bytes to numpy array
  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)
  # decode numpy array into OpenCV BGR image
  img = cv2.imdecode(jpg_as_np, flags=1)

  return img

# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream
def bbox_to_bytes(bbox_array):
  """
  Params:
          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.
  Returns:
        bytes: Base64 image byte string
  """
  # convert array into PIL image
  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')
  iobuf = io.BytesIO()
  # format bbox into png for return
  bbox_PIL.save(iobuf, format='png')
  # format return string
  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))

"""

*   Captura la imagen de la cámara, detecta rostros en la imagen, y verifica si hay coincidencias con las imágenes conocidas cargadas previamente. Luego, guarda la imagen con los nombres de las personas reconocidas.List item
*    abre la cámara, permite capturar una imagen, detecta rostros, verifica si alguno coincide con los rostros conocidos, dibuja recuadros y nombres sobre los rostros reconocidos, y guarda la imagen.

"""

# Función para tomar la foto de la cámara y realizar el reconocimiento facial
def take_photo(known_face_encodings, known_face_names, filename='photo.jpg', quality=0.8):
    js = Javascript('''
        async function takePhoto(quality) {
            const div = document.createElement('div');
            const capture = document.createElement('button');
            capture.textContent = 'Capture';
            div.appendChild(capture);
            const video = document.createElement('video');
            video.style.display = 'block';
            const stream = await navigator.mediaDevices.getUserMedia({video: true});
            document.body.appendChild(div);
            div.appendChild(video);
            video.srcObject = stream;
            await video.play();
            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);
            await new Promise((resolve) => capture.onclick = resolve);
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            stream.getVideoTracks()[0].stop();
            div.remove();
            return canvas.toDataURL('image/jpeg', quality);
        }
    ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))  # Captura la imagen desde la cámara
    img = js_to_image(data) # Convierte la imagen a formato OpenCV

    # Detectar y comparar caras
    face_locations = face_recognition.face_locations(img, model='hog')  # # Detecta las ubicaciones de los rostros en la imagen
    face_encodings = face_recognition.face_encodings(img, face_locations) # Codifica las características de cada rostro
    # Comparar rostros detectados con rostros conocidos
    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)
        name = "Unknown" # Asume inicialmente que el rostro es desconocido
        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding) # Calcula las distancias
        best_match_index = np.argmin(face_distances)
        if matches[best_match_index]: # Si hay coincidencia, asigna el nombre conocido
            name = known_face_names[best_match_index]
 # Dibuja un recuadro alrededor del rostro detectado y coloca el nombre de la persona
        cv2.rectangle(img, (left, top), (right, bottom), (0, 0, 255), 2)
        cv2.rectangle(img, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)
        font = cv2.FONT_HERSHEY_DUPLEX
        cv2.putText(img, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)

    cv2.imwrite(filename, img) # Guarda la imagen procesada con nombres en el archivo `filename`
    return filename

from google.colab import drive
drive.mount('/content/drive')

"""Recorre una carpeta que contiene subcarpetas de imágenes de diferentes personas. Cada subcarpeta se supone que corresponde a un individuo y tiene su nombre.
carga imágenes de cada persona, calcula las características de cada rostro y almacena tanto las codificaciones como los nombres en listas (known_face_encodings y known_face_names) para luego realizar la comparación.


"""

# Cargar imágenes de la carpeta y obtener encodings
known_face_encodings = []
known_face_names = []
folder_path = '/content/drive/MyDrive/FAMILIA' # Ruta de la carpeta con subcarpetas de rostros conocidos

import os
# Carga cada imagen y guarda la codificación y el nombre de la persona
for person_name in os.listdir(folder_path):
    person_folder = os.path.join(folder_path, person_name)
    if os.path.isdir(person_folder):  #Verifica que sea una carpeta
        for image_name in os.listdir(person_folder):  # Itera sobre cada imagen en la carpeta de la persona
            image_path = os.path.join(person_folder, image_name)  # Carga la imagen
            image = face_recognition.load_image_file(image_path) # Codifica el rostro
            encoding = face_recognition.face_encodings(image)
            if encoding: # Si hay un rostro encontrado
                known_face_encodings.append(encoding[0]) # Agrega la codificación a la lista
                known_face_names.append(person_name) # Asocia el nombre con la codificación

# Toma la foto de la cámara y realiza reconocimiento facial
try:
    filename = take_photo(known_face_encodings, known_face_names, 'photo.jpg')
    print('Saved to {}'.format(filename))
    display(Image(filename))  # Muestra la imagen con los rostros reconocidos
except Exception as err:
    print(str(err)) # Muestra errores en caso de que la cámara no esté disponible o haya un problema